import streamlit as st
import os
from langchain_chroma import Chroma
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.base import Embeddings
import hashlib

st.set_page_config(
    page_title="Akademik Asistan",
    page_icon="ğŸ¤–",
    layout="wide"
)

class SimpleHashEmbeddings(Embeddings):
    """Basit hash tabanlÄ± embedding - model indirmeye gerek yok"""
    
    def __init__(self, dimension=384):
        self.dimension = dimension
    
    def embed_documents(self, texts):
        embeddings = []
        for text in texts:
            hash_obj = hashlib.sha256(text.encode())
            hash_bytes = hash_obj.digest()
            vector = [float(b) / 255.0 for b in hash_bytes[:self.dimension]]
            vector += [0.0] * (self.dimension - len(vector))
            embeddings.append(vector)
        return embeddings
    
    def embed_query(self, text):
        return self.embed_documents([text])[0]

@st.cache_resource
def setup_rag_system(api_key):
    if not api_key:
        st.error("âŒ GROQ_API_KEY bulunamadÄ±.")
        return None
    
    st.info("ğŸš€ Sistem baÅŸlatÄ±lÄ±yor...")
    
    embedding_model = SimpleHashEmbeddings(dimension=256)
    
    llm = ChatGroq(
        model="llama-3.1-8b-instant",
        groq_api_key=api_key,
        temperature=0.1
    )
    
    st.info("ğŸ“š Akademik makaleler yÃ¼kleniyor...")
    
    # Veri setini kaldÄ±rÄ±yoruz, sadece demo verisi kullanÄ±yoruz
    rag_documents = [
        Document(
            page_content="""Yapay Zeka ve Makine Ã–ÄŸrenmesi
            
Yapay zeka (AI), bilgisayarlarÄ±n insan zekasÄ±nÄ± taklit etmesini saÄŸlayan bir teknolojidir. Makine Ã¶ÄŸrenmesi, yapay zekanÄ±n bir alt dalÄ±dÄ±r ve bilgisayarlarÄ±n deneyimlerden Ã¶ÄŸrenmesini saÄŸlar.

Temel Kavramlar:
- Denetimli Ã–ÄŸrenme: Etiketli verilerle eÄŸitim
- Denetimsiz Ã–ÄŸrenme: EtiketlenmemiÅŸ verilerde Ã¶rÃ¼ntÃ¼ bulma
- PekiÅŸtirmeli Ã–ÄŸrenme: Deneme yanÄ±lma ile Ã¶ÄŸrenme

Uygulamalar:
GÃ¶rÃ¼ntÃ¼ tanÄ±ma, doÄŸal dil iÅŸleme, otonom araÃ§lar, tÄ±bbi teÅŸhis sistemleri.""",
            metadata={"source": "AI_Basics", "doc_id": 0, "title": "Yapay Zeka Temelleri"}
        ),
        Document(
            page_content="""Derin Ã–ÄŸrenme ve Yapay Sinir AÄŸlarÄ±

Derin Ã¶ÄŸrenme, Ã§ok katmanlÄ± yapay sinir aÄŸlarÄ± kullanarak karmaÅŸÄ±k problemleri Ã§Ã¶zen bir makine Ã¶ÄŸrenmesi tekniÄŸidir.

Ã–nemli Mimariler:
- KonvolÃ¼syonel Sinir AÄŸlarÄ± (CNN): GÃ¶rÃ¼ntÃ¼ iÅŸleme iÃ§in
- Tekrarlayan Sinir AÄŸlarÄ± (RNN): Zaman serisi ve dil modelleme iÃ§in
- Transformer: Modern dil modelleri (GPT, BERT) iÃ§in

BaÅŸarÄ± Hikayeleri:
AlphaGo, GPT serisi, DALL-E, ChatGPT gibi sistemler derin Ã¶ÄŸrenme ile geliÅŸtirilmiÅŸtir.

Zorluklar:
YÃ¼ksek hesaplama maliyeti, bÃ¼yÃ¼k veri ihtiyacÄ±, aÃ§Ä±klanabilirlik sorunlarÄ±.""",
            metadata={"source": "Deep_Learning", "doc_id": 1, "title": "Derin Ã–ÄŸrenme"}
        ),
        Document(
            page_content="""DoÄŸal Dil Ä°ÅŸleme (NLP)

DoÄŸal dil iÅŸleme, bilgisayarlarÄ±n insan dilini anlamasÄ± ve iÅŸlemesi iÃ§in kullanÄ±lan yapay zeka dalÄ±dÄ±r.

Temel GÃ¶revler:
- Metin sÄ±nÄ±flandÄ±rma
- Duygu analizi
- Makine Ã§evirisi
- Soru-cevap sistemleri
- Metin Ã¼retimi

Modern YaklaÅŸÄ±mlar:
Transformer mimarisi ve transfer Ã¶ÄŸrenme, NLP'de devrim yaratmÄ±ÅŸtÄ±r. BERT, GPT gibi modeller, Ã¶nceden eÄŸitilmiÅŸ bÃ¼yÃ¼k dil modelleridir.

TÃ¼rkÃ§e NLP:
TÃ¼rkÃ§e morfolojik aÃ§Ä±dan zengin bir dildir. Ek yapÄ±sÄ±, NLP gÃ¶revlerini zorlaÅŸtÄ±rÄ±r ancak son yÄ±llarda TÃ¼rkÃ§e iÃ§in Ã¶zel modeller geliÅŸtirilmiÅŸtir.""",
            metadata={"source": "NLP", "doc_id": 2, "title": "DoÄŸal Dil Ä°ÅŸleme"}
        ),
        Document(
            page_content="""BilgisayarlÄ± GÃ¶rÃ¼

BilgisayarlÄ± gÃ¶rÃ¼, makinelerin gÃ¶rsel dÃ¼nyayÄ± anlamasÄ±nÄ± saÄŸlayan yapay zeka alanÄ±dÄ±r.

Temel Uygulamalar:
- Nesne tanÄ±ma ve tespiti
- YÃ¼z tanÄ±ma
- GÃ¶rÃ¼ntÃ¼ segmentasyonu
- Otonom araÃ§ navigasyonu
- TÄ±bbi gÃ¶rÃ¼ntÃ¼ analizi

Teknolojiler:
CNN'ler, gÃ¶rÃ¼ntÃ¼ iÅŸlemede en baÅŸarÄ±lÄ± modellerdir. ResNet, YOLO, U-Net gibi mimariler farklÄ± gÃ¶revlerde kullanÄ±lÄ±r.

Gelecek Trendler:
3D gÃ¶rÃ¼, video analizi, gerÃ§ek zamanlÄ± iÅŸleme.""",
            metadata={"source": "Computer_Vision", "doc_id": 3, "title": "BilgisayarlÄ± GÃ¶rÃ¼"}
        ),
        Document(
            page_content="""RAG (Retrieval Augmented Generation)

RAG, bÃ¼yÃ¼k dil modellerinin bilgi tabanÄ±ndan ilgili belgeleri alÄ±p yanÄ±t Ã¼retmesini saÄŸlayan bir tekniktir.

NasÄ±l Ã‡alÄ±ÅŸÄ±r:
1. KullanÄ±cÄ± sorusu alÄ±nÄ±r
2. Embedding ile vektÃ¶r haline getirilir
3. VektÃ¶r veritabanÄ±nda benzer belgeler aranÄ±r
4. Bulunan belgeler LLM'e context olarak verilir
5. LLM, context kullanarak yanÄ±t Ã¼retir

Avantajlar:
- GÃ¼ncel bilgi kullanÄ±mÄ±
- HallÃ¼sinasyon azalmasÄ±
- Domain-specific bilgi
- Kaynak gÃ¶sterme

Bu chatbot da RAG mimarisi kullanmaktadÄ±r.""",
            metadata={"source": "RAG_Tech", "doc_id": 4, "title": "RAG Teknolojisi"}
        )
    ]
    
    st.success(f"âœ… {len(rag_documents)} demo makalesi yÃ¼klendi!")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", ". ", " "]
    )
    chunks = text_splitter.split_documents(rag_documents)
    
    st.info(f"ğŸ“Š {len(chunks)} metin parÃ§asÄ± oluÅŸturuldu...")
    
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embedding_model,
        persist_directory="/tmp/chroma_db"
    )
    
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    system_prompt = """Sen TÃ¼rkÃ§e konuÅŸan bilimsel makale uzmanÄ± bir assistantsÄ±n. 

GÃ¶revin:
- Sadece verilen baÄŸlam kullanarak cevap ver
- TÃ¼rkÃ§e ve anlaÅŸÄ±lÄ±r bir dil kullan
- Bilimsel terimleri aÃ§Ä±kla
- Emin olmadÄ±ÄŸÄ±n konularda "Bu bilgi verilen metinde bulunmuyor" de

BaÄŸlam: {context}"""
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])
    
    document_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, document_chain)
    
    st.success("âœ… RAG Sistemi HazÄ±r! ArtÄ±k soru sorabilirsiniz.")
    return rag_chain

st.title("ğŸ”¬ Bilimsel Makale Ã–zetleyici Chatbot")
st.markdown("**Gemini Flash ve RAG mimarisi** ile bilimsel makalelerden Ã¶zetler Ã§Ä±karÄ±r.")

with st.expander("â„¹ï¸ NasÄ±l KullanÄ±lÄ±r?"):
    st.markdown("""
    1. **Makale hakkÄ±nda soru sorun:** "Yapay zeka nedir?"
    2. **Ã–zet isteyin:** "Bu makaleleri Ã¶zetle"
    3. **KarÅŸÄ±laÅŸtÄ±rma yapÄ±n:** "Hangi yÃ¶ntemler kullanÄ±lmÄ±ÅŸ?"
    
    **Not:** Chatbot sadece yÃ¼klenen makalelerden bilgi verir.
    """)

def get_huggingface_secret():
    try:
        api_key = os.environ.get("GROQ_API_KEY")
        if api_key:
            return api_key
        try:
            api_key = st.secrets["GROQ_API_KEY"]
            return api_key
        except:
            pass
        return None
    except Exception as e:
        st.error(f"Secret alma hatasÄ±: {e}")
        return None

groq_api_key = get_huggingface_secret()

if groq_api_key:
    st.success("âœ… API Key bulundu!")
    
    rag_chain = setup_rag_system(groq_api_key)
    
    if rag_chain:
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        if prompt := st.chat_input("Makalelerle ilgili soru sorun (Ã¶rn: 'Yapay zeka nedir?')"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("ğŸ” Makaleler aranÄ±yor ve cevap oluÅŸturuluyor..."):
                    try:
                        response = rag_chain.invoke({"input": prompt})
                        answer = response['answer']
                        
                        sources = response.get('context', [])
                        if sources:
                            answer += f"\n\nğŸ“š **Kaynak:** {len(sources)} makale parÃ§asÄ±ndan bilgi kullanÄ±ldÄ±."
                    except Exception as e:
                        answer = f"âŒ Bir hata oluÅŸtu: {str(e)}\n\nLÃ¼tfen soruyu yeniden deneyin."
                
                st.markdown(answer)
            
            st.session_state.messages.append({"role": "assistant", "content": answer})
        
        if st.session_state.messages:
            if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
                st.session_state.messages = []
                st.rerun()
else:
    st.error("""
    âŒ **GROQ_API_KEY bulunamadÄ±!**
    
    **Ãœcretsiz Groq API Key almak iÃ§in:**
    1. https://console.groq.com/keys adresine git
    2. Sign up ile Ã¼ye ol (Ã¼cretsiz)
    3. Create API Key tÄ±kla
    4. Key'i kopyala
    
    **Hugging Face Spaces'e ekle:**
    1. Space Settings â†’ Repository secrets
    2. New secret: `GROQ_API_KEY` = `gsk_...`
    3. SayfayÄ± yenile
    
    **Neden Groq?**
    - Tamamen Ã¼cretsiz
    - Ã‡ok hÄ±zlÄ± (Gemini'den 10x hÄ±zlÄ±)
    - Llama 3 modeli kullanÄ±yor
    """)
    
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ”§ Sistem Bilgisi")
st.sidebar.info("""
**Model:** Llama 3.1 (8B Instant)  
**API:** Groq (Ãœcretsiz)  
**Embedding:** Hash-based  
**Veri:** 5 demo makalesi  
**RAG Framework:** LangChain
""")